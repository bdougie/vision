# VisionFrameAnalyzer ğŸ“¹ğŸ–¼ï¸  
**Extract frames from videos and analyze them using AI-powered image recognition.**  

## ğŸš€ Overview  
VisionFrameAnalyzer is a Go-based tool that:  
âœ… Extracts frames from a video at set intervals using `ffmpeg`  
âœ… Uses an AI-powered vision model to analyze and describe each frame  
âœ… Provides a structured pipeline for video-to-image processing  

## âœ¨ Features  
- ğŸ **Frame Extraction** â€“ Converts video frames into images  
- ğŸ–¼ **AI-Powered Analysis** â€“ Describes each frame using an LLM vision model  
- âš¡ **Multi-Frame Processing** â€“ Handles multiple frames efficiently  
- ğŸ“ **Detailed Logging** â€“ Provides structured logs for debugging  

## ğŸ›  Tech Stack  
- **Go (Golang)**  
- **FFmpeg** (Frame Extraction)  
- **Ollama** (LLM-powered image analysis)  
- **Slog + Tint** (Logging)  
- **Kubernetes Ready** (Optional Multi-Cluster Support)  

## ğŸ“¦ Installation & Setup

### Prerequisites
- Go (1.21+ recommended)
- FFmpeg
- Ollama

If you don't have Go installed or are experiencing GOROOT issues, install/fix it first:
```sh
# macOS with Homebrew
brew install go

# Verify installation
go version

# If you see GOROOT errors, set it explicitly in your shell profile
echo 'export GOROOT=$(brew --prefix go)/libexec' >> ~/.zshrc  # or ~/.bash_profile
echo 'export PATH=$PATH:$GOROOT/bin:$HOME/go/bin' >> ~/.zshrc
source ~/.zshrc  # or source ~/.bash_profile
```

### Option 1: Local Installation
#### **MacOS (Homebrew)**
```sh
brew install ffmpeg
brew install ollama
go mod tidy
```

### Option 2: Run Directly (No Installation)
```sh
# Navigate to project directory
cd /path/to/vision

# Build and run in one step
go run ./cmd/visionanalyzer --video path/to/video.mp4 --output output_directory

# Or build an executable and run it
go build -o ./bin/visionanalyzer ./cmd/visionanalyzer
./bin/visionanalyzer --video path/to/video.mp4 --output output_directory
```

### Option 3: Docker Installation
```sh
# Build the container
docker build -t vision-analyzer .

# Run the container
docker run -v $(pwd):/data vision-analyzer --video /data/input.mp4 --output /data/frames
```

## ğŸ”§ Configuration & Usage

### Ollama Setup
1. Ensure Ollama is running locally on port 11434
2. The tool uses `llama3.2-vision:11b` model by default

### Command Line Flags
- `--video`: Path to input video file (required)
- `--output`: Output directory for frames (default: "output_frames")

### Basic Usage
```sh
# Build and run directly
go build -o visionanalyzer ./cmd/visionanalyzer
./visionanalyzer --video path/to/video.mp4

# Or run without building
go run ./cmd/visionanalyzer --video path/to/video.mp4

# Specify custom output directory
./visionanalyzer --video path/to/video.mp4 --output custom_output
```

# Show help
go run main.go --help
```

## ğŸ“‚ Output Structure
```
output_frames/
â””â”€â”€ video_name/
    â”œâ”€â”€ frame_0001.jpg
    â”œâ”€â”€ frame_0002.jpg
    â”œâ”€â”€ analysis_results.json
    â””â”€â”€ ...
```

### Analysis Results Format
The `analysis_results.json` file contains frame-by-frame analysis:
```json
[
  {
    "frame": "frame_0001.jpg",
    "content": "Detailed analysis of frame contents..."
  }
]
```

## ğŸ“ Project Structure
```
vision/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ visionanalyzer/      # Main executable package
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ analyzer/            # AI vision analysis functionality
â”‚   â”œâ”€â”€ extractor/           # Video frame extraction functionality
â”‚   â”œâ”€â”€ models/              # Shared data structures
â”‚   â””â”€â”€ storage/             # Result storage and persistence
```

## ğŸ“Œ Use Cases

ğŸ“½ï¸ Automated Video Analysis â€“ Extract insights from video feeds  
ğŸ” Content Moderation â€“ Detect and describe images in video content  
ğŸ›  Machine Learning Pipelines â€“ Pre-process video datasets for AI models  

## ğŸ“œ License

MIT License. See LICENSE for details.
